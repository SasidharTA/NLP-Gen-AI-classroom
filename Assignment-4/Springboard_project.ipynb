{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30d627e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/sasidhar.chennup/Documents/Tiger-Training/NLP-GenAI-Classroom/NLP-Gen-AI-classroom/Assignment-4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d3cbd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/sasidhar.chennup/Documents/Tiger-Training/NLP-GenAI-Classroom/NLP-Gen-AI-classroom/.nlp-genai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments\n",
    "from transformers.trainer_utils import IntervalStrategy, SaveStrategy\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from trl import SFTTrainer\n",
    "import evaluate\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b71d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device</th>\n",
       "      <th>date_</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>ram_usage</th>\n",
       "      <th>diskio_usage</th>\n",
       "      <th>question_0</th>\n",
       "      <th>insight_0</th>\n",
       "      <th>question_1</th>\n",
       "      <th>insight_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>insight_2</th>\n",
       "      <th>serialnumber_org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Device_1</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>7.845169</td>\n",
       "      <td>52.662081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What does the data contains and say about. Res...</td>\n",
       "      <td>The data contains information about a computer...</td>\n",
       "      <td>What are the top 3 most important insights</td>\n",
       "      <td>1. The highest CPU usage was recorded on 2022-...</td>\n",
       "      <td>What are the top 3 abberations present in the ...</td>\n",
       "      <td>1. The diskio_usage column has no data (NaN) f...</td>\n",
       "      <td>1BBZ4Y2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Device_1</td>\n",
       "      <td>2022-08-03</td>\n",
       "      <td>5.029416</td>\n",
       "      <td>53.519746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1BBZ4Y2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Device_1</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>4.855019</td>\n",
       "      <td>53.656122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1BBZ4Y2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Device_1</td>\n",
       "      <td>2022-08-05</td>\n",
       "      <td>8.014844</td>\n",
       "      <td>55.245124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1BBZ4Y2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Device_1</td>\n",
       "      <td>2022-08-07</td>\n",
       "      <td>16.909919</td>\n",
       "      <td>54.216115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1BBZ4Y2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5276</th>\n",
       "      <td>Device_215</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.005963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GUI43W95GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>Device_215</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.829685</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GUI43W95GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>Device_215</td>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.540792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GUI43W95GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>Device_215</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.175451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GUI43W95GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>Device_215</td>\n",
       "      <td>2022-05-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.522167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GUI43W95GE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5281 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          device      date_  cpu_usage  ram_usage  diskio_usage  \\\n",
       "0       Device_1 2022-08-02   7.845169  52.662081           NaN   \n",
       "1       Device_1 2022-08-03   5.029416  53.519746           NaN   \n",
       "2       Device_1 2022-08-04   4.855019  53.656122           NaN   \n",
       "3       Device_1 2022-08-05   8.014844  55.245124           NaN   \n",
       "4       Device_1 2022-08-07  16.909919  54.216115           NaN   \n",
       "...          ...        ...        ...        ...           ...   \n",
       "5276  Device_215 2022-05-25        NaN        NaN     90.005963   \n",
       "5277  Device_215 2022-05-26        NaN        NaN     75.829685   \n",
       "5278  Device_215 2022-05-27        NaN        NaN     88.540792   \n",
       "5279  Device_215 2022-05-28        NaN        NaN     77.175451   \n",
       "5280  Device_215 2022-05-29        NaN        NaN     77.522167   \n",
       "\n",
       "                                             question_0  \\\n",
       "0     What does the data contains and say about. Res...   \n",
       "1                                                     0   \n",
       "2                                                     0   \n",
       "3                                                     0   \n",
       "4                                                     0   \n",
       "...                                                 ...   \n",
       "5276                                                  0   \n",
       "5277                                                  0   \n",
       "5278                                                  0   \n",
       "5279                                                  0   \n",
       "5280                                                  0   \n",
       "\n",
       "                                              insight_0  \\\n",
       "0     The data contains information about a computer...   \n",
       "1                                                     0   \n",
       "2                                                     0   \n",
       "3                                                     0   \n",
       "4                                                     0   \n",
       "...                                                 ...   \n",
       "5276                                                  0   \n",
       "5277                                                  0   \n",
       "5278                                                  0   \n",
       "5279                                                  0   \n",
       "5280                                                  0   \n",
       "\n",
       "                                      question_1  \\\n",
       "0     What are the top 3 most important insights   \n",
       "1                                              0   \n",
       "2                                              0   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "...                                          ...   \n",
       "5276                                           0   \n",
       "5277                                           0   \n",
       "5278                                           0   \n",
       "5279                                           0   \n",
       "5280                                           0   \n",
       "\n",
       "                                              insight_1  \\\n",
       "0     1. The highest CPU usage was recorded on 2022-...   \n",
       "1                                                     0   \n",
       "2                                                     0   \n",
       "3                                                     0   \n",
       "4                                                     0   \n",
       "...                                                 ...   \n",
       "5276                                                  0   \n",
       "5277                                                  0   \n",
       "5278                                                  0   \n",
       "5279                                                  0   \n",
       "5280                                                  0   \n",
       "\n",
       "                                             question_2  \\\n",
       "0     What are the top 3 abberations present in the ...   \n",
       "1                                                     0   \n",
       "2                                                     0   \n",
       "3                                                     0   \n",
       "4                                                     0   \n",
       "...                                                 ...   \n",
       "5276                                                  0   \n",
       "5277                                                  0   \n",
       "5278                                                  0   \n",
       "5279                                                  0   \n",
       "5280                                                  0   \n",
       "\n",
       "                                              insight_2 serialnumber_org  \n",
       "0     1. The diskio_usage column has no data (NaN) f...          1BBZ4Y2  \n",
       "1                                                     0          1BBZ4Y2  \n",
       "2                                                     0          1BBZ4Y2  \n",
       "3                                                     0          1BBZ4Y2  \n",
       "4                                                     0          1BBZ4Y2  \n",
       "...                                                 ...              ...  \n",
       "5276                                                  0       GUI43W95GE  \n",
       "5277                                                  0       GUI43W95GE  \n",
       "5278                                                  0       GUI43W95GE  \n",
       "5279                                                  0       GUI43W95GE  \n",
       "5280                                                  0       GUI43W95GE  \n",
       "\n",
       "[5281 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df=pd.read_excel(\"Table Insights/table_insights_labeled_data.xlsx\")\n",
    "# df.rename(columns={df.columns[0]: \"device\"}, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80812c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# summarizer=pipeline(\"text2text-generation\",model=\"google/flan-t5-base\")\n",
    "\n",
    "# #summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMPTS = [\n",
    "#     \"Summarize the dataset focusing on CPU, RAM, and Disk performance.\",\n",
    "#     \"Write a short report explaining the system behavior over time.\",\n",
    "#     \"Generate business-level insights based on device performance trends.\",\n",
    "#     \"Summarize any anomalies or outliers in the dataset.\",\n",
    "#     \"Create a technical summary of how system resources were used.\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be7fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def table_to_text(row):\n",
    "    # return f\"Device {row['device']} had CPU usage {row['cpu_usage']:.2f}% and RAM usage {row['ram_usage']:.2f}% on {row['date_']}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c8128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts=[table_to_text(row) for _,row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_text=\" \".join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary=summarizer(f\"Summarize this device usage data and provide 3 business insights:\\n{input_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc7cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      ": Device Device_1 had CPU usage 8.01% and RAM usage 53.52% on 2022-08-04 00:00:00. Device Device_1 had CPU usage 4.86% and RAM usage 53.52% on 2022-08-04 00:00:00. Device Device_1 had CPU usage 8.01% and RAM usage 53.52% on 2022-08-04 00:00:00. Device Device_1 had CPU usage 16.91% and RAM usage 54.22% on 2022-08-05 00:00:00. Device Device_1 had CPU usage 8.01% and RAM usage 53.52% on 2022-08-07 00:00:00. Device Device_1 had CPU usage 6.91% and RAM usage 62.33% on 2022-08-10 00:00:00. Device Device_1 had CPU usage 7.50% and RAM usage 63.40% on 2022-08-11 00:00:00. Device\n"
     ]
    }
   ],
   "source": [
    "# print(\"Generated Summary:\\n:\",summary[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12482105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Prompt 1 Result:\n",
      " Device Device_1 had CPU usage 5.03% and RAM usage 52.66% on 2022-08-02 00:00:00. Device Device_1 had CPU usage 4.86% and RAM usage 53.52% on 2022-08-04 00:00:00. Device Device_1 had CPU usage 8.01% and RAM usage 53.52% on 2022-08-04 00:00:00. Device Device_1 had CPU usage 16.91% and RAM usage 55.25% on 2022-08-05 00:00:00. Device Device_1 had CPU usage 8.01% and RAM usage 55.32% on 2022-08-07 00:00:00. Device Device_1 had CPU usage 6.97% and RAM usage 59.46% on 2022-08-09 00:00:00. Device Device_1 had CPU usage 6.91% and RAM usage 62.33% on 2022-08-10 00:\n",
      "\n",
      "ðŸ”¹ Prompt 2 Result:\n",
      " Device Device_1 had CPU usage 7.81% and RAM usage 66.83% on 2022-08-21 00:00:00.\n",
      "\n",
      "ðŸ”¹ Prompt 3 Result:\n",
      " Device Device_1 had CPU usage 8.01% and RAM usage 53.52% on 2022-08-04 00:00:00. Device Device_1 had CPU usage 4.86% and RAM usage 53.52% on 2022-08-04 00:00:00. Device Device_1 had CPU usage 4.86% and RAM usage 53.52% on 2022-08-04 00:00:00. Device Device_1 had CPU usage 8.01% and RAM usage 53.52% on 2022-08-04 00:00:00. Device Device_1 had CPU usage 6.97% and RAM usage 59.46% on 2022-08-07 00:00:00. Device Device_1 had CPU usage 6.95% and RAM usage 62.33% on 2022-08-10 00:00:00. Device Device_1 had CPU usage 7.50% and RAM usage 63.40% on 2022-08-15 00:00:00.\n"
     ]
    }
   ],
   "source": [
    "# prompt_1 = f\"Summarize CPU and RAM usage trends and identify anomalies:\\n{input_text}\"\n",
    "# prompt_2 = f\"Provide actionable business insights from the following machine usage table:\\n{input_text}\"\n",
    "# prompt_3 = f\"Write a concise report on system performance trends and abnormalities:\\n{input_text}\"\n",
    "\n",
    "# for i, prompt in enumerate([prompt_1, prompt_2, prompt_3], 1):\n",
    "#     result = summarizer(prompt)\n",
    "#     print(f\"\\nðŸ”¹ Prompt {i} Result:\\n\", result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74089121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_random_sample(df, frac=0.4):\n",
    "#     return df.sample(frac=frac, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48662c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def summarize_table(df,pt,temperature=0.8):\n",
    "#     prompt = pt\n",
    "#     sample_df = get_random_sample(df)\n",
    "#     context = sample_df.head(5).to_string(index=False)\n",
    "\n",
    "#     full_input = f\"\"\"\n",
    "#     You are a data analyst.\n",
    "#     The following is a table showing device usage statistics.\n",
    "#     Based on the data, {prompt}\n",
    "\n",
    "#     Table:\n",
    "#     {context}\n",
    "#     \"\"\"\n",
    "\n",
    "#     output = summarizer(full_input, max_length=150, min_length=40, do_sample=True, temperature=temperature)[0]['generated_text']\n",
    "\n",
    "#     print(f\"ðŸ§¾ Prompt: {prompt}\\n\")\n",
    "#     print(\"ðŸ“Š Summary:\\n\", output)\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4de9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¾ Prompt: Summarize the dataset focusing on CPU, RAM, and Disk performance.\n",
      "\n",
      "ðŸ“Š Summary:\n",
      " Device_42 2023-03-17 12.971891 62.290418 5.299380 0 0 0 0 0 5CD127F945 Device_38 2022-08-31 2.259321 10.787057 NaN 0 0 0 0 0 0 0 4CE9241B5C Device_112 2023-03-27 11.216762 72.827133 1.949365 0 0 0 0 0 0 0 0 7O2JJQMD8J Device_147 2022-04-30 34.880517 NaN 0 0 0 0 0 0 0 0 7O2JJQMD8J\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¾ Prompt: Write a short report explaining the system behavior over time.\n",
      "\n",
      "ðŸ“Š Summary:\n",
      " Device_48 2022-02-01 NaN 11.721103 NaN 0 0 0 0 0 0 0 74KG71NYHC Device_21 2022-05-17 NaN NaN 89.824853 0 0 0 0 0 0 0 0 E6VESLF8UI Device_191 2022-06-10 5.888569 48.679107 NaN 0 0 0 0 0 0 0 0 MXL9233F04 Device_93 2022-07-02 NaN NaN 16.780572 0 0 0 0 0 0 0 0 R5FSIKUTS6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¾ Prompt: Generate business-level insights based on device performance trends.\n",
      "\n",
      "ðŸ“Š Summary:\n",
      " 5CD0139WZ2 CPU Usage Variability: CPU Usage varies significantly across the dataset, ranging from 6.75% to 20.15%.nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¾ Prompt: Summarize any anomalies or outliers in the dataset.\n",
      "\n",
      "ðŸ“Š Summary:\n",
      " Device_6 2023-03-05 63.617553 48.875857 1.339953 0 0 0 0 0 0 MXL0404FWG Device_26 2022-08-04 30.964149 84.776425 NaN 0 0 0 0 0 0 5CG839181R Device_83 2023-03-25 7.782140 69.247028 1.037882 0 0 0 0 0 0 0 5CG1092DC0 Device_212 2023-03-16 9.754410 81.015184 5.004808 0 0 0 0 0 0 0 ZK016729U\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¾ Prompt: Create a technical summary of how system resources were used.\n",
      "\n",
      "ðŸ“Š Summary:\n",
      " Device_160 2022-08-23 24.701188 76.204835 NaN 0 0 0 0 0 0 5CG8224YM4 Device_174 2023-03-22 6.521767 79.398007 1.833206 0 0 0 0 0 0 0 9T688EZ74Y Device_181 2022-10-14 NaN NaN 70.233007 0 0 0 0 0 0 0 9T688EZ74Y Device_61 2022-05-27 15.085230 NaN NaN 0 0 0 0 0 0 0 62NVDZ3HEK Device_122 2023-03-13 46.341837 49.944305 28.456247 0 0 0 0 0 0 0 5CG2213810\n"
     ]
    }
   ],
   "source": [
    "# for i in PROMPTS:\n",
    "#     summary = summarize_table(df,pt=i,temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90e7382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/mnt/c/Users/sasidhar.chennup/Documents/Tiger-Training/NLP-GenAI-Classroom/NLP-Gen-AI-classroom/Assignment-4/mlruns/308567176882587203', creation_time=1762598374337, experiment_id='308567176882587203', last_update_time=1762598374337, lifecycle_stage='active', name='IT-Giant_Table-to-Insights', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "MAX_SEQ_LENGTH = 1024\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "NUM_TRAIN_EPOCHS = 3\n",
    "LR = 2e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Initialize MLflow Tracking\n",
    "# We use a local tracking URI for Colab\n",
    "MLFLOW_TRACKING_URI = \"mlruns\"\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(\"IT-Giant_Table-to-Insights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4555a67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'summary', '__index_level_0__']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_175444/2514243728.py:41: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_processed = df_raw.groupby('group_id').apply(group_and_serialize_logs).reset_index()\n"
     ]
    }
   ],
   "source": [
    "#DATA LOADING, SERIALIZATION, AND SPLIT\n",
    "\n",
    "FILE_PATH = \"Table Insights/table_insights_labeled_data.xlsx\"\n",
    "df_raw = pd.read_excel(FILE_PATH)\n",
    "\n",
    "# Clean Column Names and Create Group IDs\n",
    "new_columns = list(df_raw.columns)\n",
    "new_columns[0] = 'device_log_group'\n",
    "df_raw.columns = new_columns\n",
    "df_raw.rename(columns={'serialnumber_org': 'device_serial'}, inplace=True)\n",
    "df_raw['group_id'] = df_raw['device_log_group'].ffill() + '_' + df_raw['device_serial'].astype(str)\n",
    "\n",
    "# Serialization Function (As defined previously)\n",
    "def group_and_serialize_logs(group):\n",
    "    target_row = group[(group['insight_0'] != '0') & (group['insight_0'] != 0)].head(1)\n",
    "    if target_row.empty:\n",
    "        return pd.Series({'input_prompt': None, 'target_insight': None})\n",
    "\n",
    "    target_insight = target_row['insight_0'].iloc[0]\n",
    "    kpi_cols = ['cpu_usage', 'ram_usage', 'diskio_usage']\n",
    "    agg_data = group[kpi_cols].agg(['mean', 'max', 'count']).to_dict()\n",
    "    null_counts = group[kpi_cols].isnull().sum().to_dict()\n",
    "\n",
    "    prompt_template = f\"\"\"\n",
    "    Analyze the following machine usage log data for Device: {group['device_serial'].iloc[0]}.\n",
    "    The data spans {agg_data['cpu_usage']['count']} data points.\n",
    "\n",
    "    ### Key Performance Indicators (KPIs):\n",
    "    - CPU Usage (Mean/Max): {agg_data['cpu_usage']['mean']:.2f}% / {agg_data['cpu_usage']['max']:.2f}%\n",
    "    - RAM Usage (Mean/Max): {agg_data['ram_usage']['mean']:.2f}% / {agg_data['ram_usage']['max']:.2f}%\n",
    "\n",
    "    ### Data Completeness:\n",
    "    - Disk IO Usage: {agg_data['diskio_usage']['count']} non-null entries.\n",
    "    - Missing CPU entries: {null_counts['cpu_usage']}\n",
    "\n",
    "    TASK: Generate a concise, actionable business insight (similar to the provided GPT insight_0) based on this summary.\n",
    "    \"\"\"\n",
    "    return pd.Series({'input_prompt': prompt_template.strip(), 'target_insight': target_insight})\n",
    "\n",
    "# Apply Grouping\n",
    "df_processed = df_raw.groupby('group_id').apply(group_and_serialize_logs).reset_index()\n",
    "df_processed.dropna(subset=['target_insight'], inplace=True)\n",
    "df_processed.rename(columns={'input_prompt': 'text', 'target_insight': 'summary'}, inplace=True)\n",
    "\n",
    "# Train/Test Split\n",
    "train_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "test_df_for_eval = test_df.copy()\n",
    "\n",
    "# Convert to Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'summary']])\n",
    "test_dataset = Dataset.from_pandas(test_df_for_eval[['text', 'summary']])\n",
    "print(train_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Metrics Logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "#BASE MODEL INFERENCE AND BASELINE LOGGING\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"Base_Model_ZeroShot\") as run:\n",
    "    mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "    mlflow.log_param(\"tuning_method\", \"None (Zero-Shot)\")\n",
    "    mlflow.log_param(\"max_seq_length\", MAX_SEQ_LENGTH)\n",
    "\n",
    "\n",
    "    base_model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "    base_model.to(DEVICE)\n",
    "\n",
    "    def generate_insight(prompt_text, model, tokenizer, max_length=150):\n",
    "        input_text = f\"Summarize machine usage logs into actionable business insights. INPUT: {prompt_text}\"\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=MAX_SEQ_LENGTH, truncation=True).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_length=max_length, num_beams=4, do_sample=False, early_stopping=True)\n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    # Generate Predictions\n",
    "    base_model_predictions = [generate_insight(prompt, base_model, tokenizer) for prompt in test_df_for_eval['text'].tolist()]\n",
    "    test_df_for_eval['base_prediction'] = base_model_predictions\n",
    "    references = test_df_for_eval['summary'].tolist()\n",
    "\n",
    "    # Evaluation\n",
    "    rouge_metric = evaluate.load(\"rouge\")\n",
    "    bleu_metric = evaluate.load(\"bleu\")\n",
    "    semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    def calculate_semantic_match(predictions, references, model):\n",
    "        pred_embeddings = model.encode(predictions, convert_to_tensor=True)\n",
    "        ref_embeddings = model.encode(references, convert_to_tensor=True)\n",
    "        cos_scores = util.cos_sim(pred_embeddings, ref_embeddings)\n",
    "        return np.mean([cos_scores[i, i].item() for i in range(len(predictions))])\n",
    "\n",
    "    base_rouge = rouge_metric.compute(predictions=base_model_predictions, references=references)\n",
    "    base_bleu = bleu_metric.compute(predictions=base_model_predictions, references=references, max_order=4)\n",
    "    base_semantic = calculate_semantic_match(base_model_predictions, references, semantic_model)\n",
    "\n",
    "    # Log Metrics to MLflow\n",
    "    mlflow.log_metric(\"base_bleu_4\", round(base_bleu['bleu'], 4))\n",
    "    mlflow.log_metric(\"base_rouge_l\", round(base_rouge['rougeL'], 4))\n",
    "    mlflow.log_metric(\"base_semantic_match\", round(base_semantic, 4))\n",
    "    print(\"Base Model Metrics Logged to MLflow.\")\n",
    "\n",
    "    # Save the base model results for comparison\n",
    "    test_df_for_eval[['text', 'summary', 'base_prediction']].to_csv(\"base_model_predictions.csv\", index=False)\n",
    "    mlflow.log_artifact(\"base_model_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7420e362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to remove from train_dataset: ['summary', '__index_level_0__']\n",
      "Columns to remove from test_dataset: ['summary', '__index_level_0__']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:00<00:00, 1299.38 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:00<00:00, 8485.30 examples/s]\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Adding EOS to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:00<00:00, 18092.04 examples/s]\n",
      "Tokenizing train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:00<00:00, 888.20 examples/s]\n",
      "Truncating train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:00<00:00, 8116.88 examples/s]\n",
      "Adding EOS to eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:00<00:00, 10912.75 examples/s]\n",
      "Tokenizing eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:00<00:00, 1749.64 examples/s]\n",
      "Truncating eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:00<00:00, 13263.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting LoRA Fine-Tuning ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/sasidhar.chennup/Documents/Tiger-Training/NLP-GenAI-Classroom/NLP-Gen-AI-classroom/.nlp-genai/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "#LORA FINE-TUNING AND MLFLOW LOGGING\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"LoRA_FineTuned_FlanT5\") as run:\n",
    "    # 4.1 Log Parameters\n",
    "    mlflow.log_param(\"model_name\", MODEL_NAME)\n",
    "    mlflow.log_param(\"tuning_method\", \"LoRA PEFT\")\n",
    "    mlflow.log_param(\"lora_r\", LORA_R)\n",
    "    mlflow.log_param(\"lora_alpha\", LORA_ALPHA)\n",
    "    mlflow.log_param(\"num_epochs\", NUM_TRAIN_EPOCHS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "\n",
    "    def _fix_json_serialization(obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        if isinstance(obj, tuple):\n",
    "            return list(obj)\n",
    "        raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\n",
    "\n",
    "    # 4.2 Data Formatting for SFT\n",
    "    def format_for_sft(example):\n",
    "        prompt = f\"Summarize machine usage logs into actionable business insights. INPUT: {example['text']}\"\n",
    "        target = example['summary']\n",
    "        return {\"text\": f\"{prompt} TARGET: {target}{tokenizer.eos_token}\"}\n",
    "\n",
    "    cols_to_remove = ['summary', '__index_level_0__']\n",
    "    train_cols = train_dataset.column_names\n",
    "    test_cols = test_dataset.column_names\n",
    "\n",
    "    # Filter the list to only include existing columns\n",
    "    cols_to_remove_train = [col for col in cols_to_remove if col in train_cols]\n",
    "    cols_to_remove_test = [col for col in cols_to_remove if col in test_cols]\n",
    "\n",
    "    # Apply the map function using the filtered list\n",
    "    print(f\"Columns to remove from train_dataset: {cols_to_remove_train}\")\n",
    "    print(f\"Columns to remove from test_dataset: {cols_to_remove_test}\")\n",
    "\n",
    "    train_dataset = train_dataset.map(format_for_sft, remove_columns=['summary', '__index_level_0__'])\n",
    "    test_dataset = test_dataset.map(format_for_sft, remove_columns=['summary', '__index_level_0__'])\n",
    "\n",
    "    # 4.3 Configure and Apply LoRA\n",
    "    lora_config = LoraConfig(\n",
    "        r=LORA_R, lora_alpha=LORA_ALPHA, target_modules=[\"q\", \"v\"],\n",
    "        lora_dropout=0.05, bias=\"none\", task_type=\"SEQ_2_SEQ_LM\",\n",
    "    )\n",
    "    # Log the full config as a JSON artifact\n",
    "    with open(\"lora_config.json\", \"w\") as f:\n",
    "        json.dump(lora_config.to_dict(), f,default=_fix_json_serialization)\n",
    "    mlflow.log_artifact(\"lora_config.json\")\n",
    "\n",
    "    model_for_tuning = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "    model_for_tuning = get_peft_model(model_for_tuning, lora_config)\n",
    "\n",
    "    # 4.4 Training Arguments and SFTTrainer\n",
    "    training_args = TrainingArguments(\n",
    "    output_dir=\"./lora_results\",\n",
    "    num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=LR,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"mlflow\"\n",
    ")\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model=model_for_tuning,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        processing_class=tokenizer\n",
    "    )\n",
    "\n",
    "    print(\"\\n--- Starting LoRA Fine-Tuning ---\")\n",
    "    trainer.train()\n",
    "\n",
    "    # 4.5 Save Adapter and Log Model\n",
    "    ADAPTER_PATH = \"flan_t5_table_insights_adapter\"\n",
    "    trainer.model.save_pretrained(ADAPTER_PATH)\n",
    "    tokenizer.save_pretrained(ADAPTER_PATH)\n",
    "\n",
    "    # Log the adapter weights and tokenizer to MLflow\n",
    "    mlflow.log_artifact(ADAPTER_PATH)\n",
    "    print(\"Fine-Tuned Adapter Logged to MLflow Artifacts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea613b50",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3374530825.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[28], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    with open(\"lora_config.json\", \"w\") as f:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ac72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlp-genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
